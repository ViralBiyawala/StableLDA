{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7865cd61",
   "metadata": {},
   "source": [
    "## This notebook reproduces the results reported in Section 6.1 \"Empirical study: online knowledge community\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af900d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from statsmodels.discrete.discrete_model import Poisson\n",
    "\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e2c2f",
   "metadata": {},
   "source": [
    "#### Read in original dataset, the stackexchange dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b62fff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>post</th>\n",
       "      <th>answer</th>\n",
       "      <th>post_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>post_idx</th>\n",
       "      <th>answer_idx</th>\n",
       "      <th>logwords</th>\n",
       "      <th>dummy</th>\n",
       "      <th>AnswerHepfulness</th>\n",
       "      <th>QuestionHelpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In Darksiders 3 there are many enemies who ...</td>\n",
       "      <td>&lt;p&gt;The ways I found to beat blocking enemies, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In Level 2-3 of Super Mario 3D Land, by Mar...</td>\n",
       "      <td>&lt;p&gt;You need to hit it with your Tanooki's suit...</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In massively multiplayer games, the servers...</td>\n",
       "      <td>&lt;p&gt;All MMO's have massive amounts of data in d...</td>\n",
       "      <td>46</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>3.828641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In massively multiplayer games, the servers...</td>\n",
       "      <td>&lt;p&gt;It's also a question of cost and predictabi...</td>\n",
       "      <td>46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.897840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.828641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gaming</td>\n",
       "      <td>&lt;p&gt;In massively multiplayer games, the servers...</td>\n",
       "      <td>&lt;p&gt;They may need to deploy updates to binaries...</td>\n",
       "      <td>46</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.828641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               post  \\\n",
       "0   gaming  <p>In Darksiders 3 there are many enemies who ...   \n",
       "1   gaming  <p>In Level 2-3 of Super Mario 3D Land, by Mar...   \n",
       "2   gaming  <p>In massively multiplayer games, the servers...   \n",
       "3   gaming  <p>In massively multiplayer games, the servers...   \n",
       "4   gaming  <p>In massively multiplayer games, the servers...   \n",
       "\n",
       "                                              answer  post_score  \\\n",
       "0  <p>The ways I found to beat blocking enemies, ...           0   \n",
       "1  <p>You need to hit it with your Tanooki's suit...           4   \n",
       "2  <p>All MMO's have massive amounts of data in d...          46   \n",
       "3  <p>It's also a question of cost and predictabi...          46   \n",
       "4  <p>They may need to deploy updates to binaries...          46   \n",
       "\n",
       "   answer_score  Sequence  post_idx  answer_idx  logwords  dummy  \\\n",
       "0           0.0       1.0         0         1.0  3.433987    0.0   \n",
       "1           7.0       1.0         2         3.0  1.791759    1.0   \n",
       "2          43.0       1.0         4         5.0  3.401197    1.0   \n",
       "3          21.0       2.0         4         6.0  4.897840    1.0   \n",
       "4           6.0       3.0         4         7.0  3.367296    1.0   \n",
       "\n",
       "   AnswerHepfulness  QuestionHelpfulness  \n",
       "0          0.000000             0.000000  \n",
       "1          1.945910             1.386294  \n",
       "2          3.761200             3.828641  \n",
       "3          3.044522             3.828641  \n",
       "4          1.791759             3.828641  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/stackexchange.csv', engine='python', on_bad_lines='skip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ef45a",
   "metadata": {},
   "source": [
    "#### Total number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae279ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7022"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.post.unique()) + len(df.answer.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c5056a",
   "metadata": {},
   "source": [
    "#### Read in data (the bow file and vocab file) for topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d18e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "with io.open('data/stackexchange.bow', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read().splitlines()\n",
    "\n",
    "vocabs = []\n",
    "with io.open('data/stackexchange.vocab', 'r', encoding='utf-8') as f:\n",
    "    vocabs = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f54dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "288c3f32",
   "metadata": {},
   "source": [
    "#### using StableLDA to infer topic vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d3b2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stability import *\n",
    "from stablelda import StableLDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94122a83",
   "metadata": {},
   "source": [
    "first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f58e3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_file = 'data/stackexchange.bow'\n",
    "vocab_file = 'data/stackexchange.vocab'\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 5000\n",
    "alpha, beta, eta = 1, 0.01, 1000\n",
    "epochs = 2\n",
    "rand_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79befe9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------running Stable LDA model----------\n",
      "--------- loading data ----------------\n",
      "train -f data/stackexchange.bow -v data/stackexchange.vocab -c data/output/cluster.dat -z data/output/z.dat -t 50 -w 5000 -a 1 -b 0.01 -e 1000 -n 2 -r 42 -o data/output/\n",
      "enemi team usual fight hero earli champion oppon group lane\n",
      "block repeat redston chain torch signal clock piston solid stone\n",
      "damag attack effect hit target deal charg slow mele cast\n",
      "get lot pretti littl big kind worth feel bad mind\n",
      "like wai need work want know try thing help abl\n",
      "possibl make best hard easi basic fast clear import faster\n",
      "good better great consid defens strategi improv choic benefit protect\n",
      "strong new chang charact type gener follow requir exampl allow\n",
      "unit forc tower armi turret defend troop rush scout drone\n",
      "rang speed rate critic movement break factor potenti slightli huge\n",
      "weapon shield shot gun combat heavi ammo rifl grenad fire\n",
      "file instal download data folder copi screenshot delet program librari\n",
      "alt look appear red light show box blue color bar\n",
      "ship space engin fulli storag part suppli repair vehicl attach\n",
      "right map place left locat instead line move small portal\n",
      "version updat edit origin releas dlc recent patch featur content\n",
      "area room wall near door insid walk outsid floor lead\n",
      "div video second youtub watch record seri tutori fallout skip\n",
      "time end long awai wait lose hour later longer minut\n",
      "armor hand equip enchant sword ring bow blade boot wear\n",
      "talk npc guild companion speak vampir meet bounti convers faction\n",
      "control xbox drive devic input wii usb phone disc compat\n",
      "href noreferr rel nofollow blockquot src img descript imag sourc\n",
      "server connect issu support client net internet machin port network\n",
      "code player pre command quot remov test tag object execut\n",
      "hous town home station visit bed vault apart prison dweller\n",
      "water farm tree plant food fish seed wood grow grass\n",
      "item drop bui upgrad pick trade chest monei inventori sell\n",
      "set option open kbd click window screen select kei button\n",
      "game plai mode multiplay standard super offlin pro deck style\n",
      "happen come have fix caus notic tell bug miss haven\n",
      "jump hold head shoot ground fall arrow throw face break\n",
      "got dai old year went night came track month week\n",
      "spawn monster mob summon stand villag zombi teleport anim trap\n",
      "build citi resourc research mass built product job rout tech\n",
      "dragon dark soul king hunter giant orb blood demon crystal\n",
      "skill abil stat spell bonu magic stack lvl resist combin\n",
      "complet quest mission unlock achiev final boss reach finish event\n",
      "steam account friend store onlin purchas free user live transfer\n",
      "minecraft world mod java launcher tool jar forg textur vanilla\n",
      "differ pokemon spoiler die death similar pokÃ©mon dead sort rule\n",
      "run save enter turn tri check activ start load close\n",
      "level gold card cost collect earn star obtain heart gem\n",
      "kill destroi guard soldier captur sai crew squad board rel\n",
      "power health heal extra potion life bring mana burn restor\n",
      "score battl match win rank receiv reward member clan leagu\n",
      "question answer mention exactli understand fact correct thank explain comment\n",
      "land air car stick aim rocket train fly forward straight\n",
      "mean base increas number high give valu higher affect low\n",
      "point start chanc experi gain result action success stop condit\n"
     ]
    }
   ],
   "source": [
    "# first model\n",
    "output_dir = 'data/output/'\n",
    "stablelda = StableLDA(num_topics, num_words, alpha, beta, eta, rand_seed, output_dir )\n",
    "stablelda.train(bow_file, vocab_file, epochs)\n",
    "\n",
    "docs, vocab, theta, phi = load_topic_model_results(bow_file, vocab_file,\n",
    "                                                     output_dir+'theta.dat', output_dir+'phi.dat')\n",
    "tm = TopicModel(num_topics, theta, phi, docs, vocab)\n",
    "\n",
    "tm.print_top_n_words(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8d5ce",
   "metadata": {},
   "source": [
    "generate QASimilarity variable, which is the cosine similarity between question and answer topic vector. Note: This variable can be quite unstable if it were generated by LDA model due to its instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "580b534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['post_idx'] = df['post_idx'].astype(int)\n",
    "df['answer_idx'] = df['answer_idx'].astype(int)\n",
    "df['stablelda_sim'] = df.apply(lambda x: 1 - cosine(theta[x['post_idx']], theta[x['answer_idx']]), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88212b",
   "metadata": {},
   "source": [
    "run regression: \n",
    "\n",
    "AnswerHelpfulness = $\\beta_0$ + $\\beta_1$StableLDASimilarity + $\\beta_2$Sequence + $\\beta_3$QuestionHelpfulness + $\\beta_4$log(words) + $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e78ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.371\n",
      "Model:                            OLS   Adj. R-squared:                  0.370\n",
      "Method:                 Least Squares   F-statistic:                     657.1\n",
      "Date:                Sat, 19 Oct 2024   Prob (F-statistic):               0.00\n",
      "Time:                        13:20:06   Log-Likelihood:                -5069.1\n",
      "No. Observations:                4468   AIC:                         1.015e+04\n",
      "Df Residuals:                    4463   BIC:                         1.018e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.0995      0.113     -0.878      0.380      -0.322       0.123\n",
      "stablelda_sim          -0.0047      0.114     -0.041      0.967      -0.229       0.219\n",
      "Sequence               -0.2477      0.008    -30.663      0.000      -0.264      -0.232\n",
      "QuestionHelpfulness     0.4992      0.012     42.469      0.000       0.476       0.522\n",
      "logwords                0.2195      0.013     17.000      0.000       0.194       0.245\n",
      "==============================================================================\n",
      "Omnibus:                       40.481   Durbin-Watson:                   1.950\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.902\n",
      "Skew:                           0.170   Prob(JB):                     1.60e-08\n",
      "Kurtosis:                       2.721   Cond. No.                         63.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices(' AnswerHepfulness ~ stablelda_sim  + Sequence + QuestionHelpfulness  + logwords ', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "483d1c75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.445846\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                 4468\n",
      "Model:                          Logit   Df Residuals:                     4463\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sat, 19 Oct 2024   Pseudo R-squ.:                  0.1530\n",
      "Time:                        13:20:17   Log-Likelihood:                -1992.0\n",
      "converged:                       True   LL-Null:                       -2351.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.188e-154\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.1516      0.405     -0.374      0.708      -0.946       0.643\n",
      "stablelda_sim          -0.2118      0.414     -0.512      0.609      -1.023       0.600\n",
      "Sequence               -0.5982      0.031    -19.097      0.000      -0.660      -0.537\n",
      "QuestionHelpfulness     0.5634      0.045     12.540      0.000       0.475       0.651\n",
      "logwords                0.6224      0.048     12.988      0.000       0.528       0.716\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dummy ~ stablelda_sim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcdcc3",
   "metadata": {},
   "source": [
    "Note that due to stochasticity, the regression result (effect size) may be different across runs. So the result is slightly different from that reported in Table I. Stable LDA offers much more stable results than that of LDA, in terms of effect size and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebd60a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "                       OLS      Logit  \n",
      "---------------------------------------\n",
      "Intercept           -0.099    -0.152   \n",
      "                    (0.113)   (0.405)  \n",
      "stablelda_sim       -0.005    -0.212   \n",
      "                    (0.114)   (0.414)  \n",
      "Sequence            -0.248*** -0.598***\n",
      "                    (0.008)   (0.031)  \n",
      "QuestionHelpfulness 0.499***  0.563*** \n",
      "                    (0.012)   (0.045)  \n",
      "logwords            0.220***  0.622*** \n",
      "                    (0.013)   (0.048)  \n",
      "R-squared           0.371              \n",
      "R-squared Adj.      0.370              \n",
      "AIC                 10148.    3994.1   \n",
      "Log-Likelihood      -5069.1   -1992.0  \n",
      "=======================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "results = summary_col([ols_res, logit_res],stars=True,float_format='%0.3f',\n",
    "                  model_names=['OLS', 'Logit'],\n",
    "                  info_dict={'Log-Likelihood': lambda x: \"%#8.5g\" % x.llf,\n",
    "                     'AIC': lambda x: \"%#8.5g\" % x.aic} )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157b808",
   "metadata": {},
   "source": [
    "second run. We retrain a topic model, re-calculate the QASimilarity variable, and re-run the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a97b961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------running Stable LDA model----------\n",
      "--------- loading data ----------------\n",
      "train -f data/stackexchange.bow -v data/stackexchange.vocab -c data/output/cluster.dat -z data/output/z.dat -t 50 -w 5000 -a 1 -b 0.01 -e 1000 -n 2 -r 42 -o data/output/\n"
     ]
    }
   ],
   "source": [
    "# second model\n",
    "output_dir = 'data/output/'\n",
    "random_seed = 24\n",
    "stablelda = StableLDA(num_topics, num_words, alpha, beta, eta, rand_seed, output_dir )\n",
    "stablelda.train(bow_file, vocab_file, epochs)\n",
    "\n",
    "docs, vocab, theta, phi = load_topic_model_results(bow_file, vocab_file,\n",
    "                                                     output_dir+'theta.dat', output_dir+'phi.dat')\n",
    "tm = TopicModel(num_topics, theta, phi, docs, vocab)\n",
    "\n",
    "# tm.print_top_n_words(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "312fd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stablelda_sim'] = df.apply(lambda x:1-cosine(theta[x['post_idx']], theta[x['answer_idx']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aff688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.371\n",
      "Model:                            OLS   Adj. R-squared:                  0.370\n",
      "Method:                 Least Squares   F-statistic:                     657.1\n",
      "Date:                Sat, 19 Oct 2024   Prob (F-statistic):               0.00\n",
      "Time:                        13:25:10   Log-Likelihood:                -5069.1\n",
      "No. Observations:                4468   AIC:                         1.015e+04\n",
      "Df Residuals:                    4463   BIC:                         1.018e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.1142      0.110     -1.034      0.301      -0.331       0.102\n",
      "stablelda_sim           0.0116      0.111      0.105      0.917      -0.206       0.229\n",
      "Sequence               -0.2477      0.008    -30.660      0.000      -0.264      -0.232\n",
      "QuestionHelpfulness     0.4992      0.012     42.471      0.000       0.476       0.522\n",
      "logwords                0.2202      0.013     17.054      0.000       0.195       0.245\n",
      "==============================================================================\n",
      "Omnibus:                       40.489   Durbin-Watson:                   1.950\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.922\n",
      "Skew:                           0.170   Prob(JB):                     1.58e-08\n",
      "Kurtosis:                       2.721   Cond. No.                         61.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## linear regression\n",
    "y, X = dmatrices('AnswerHepfulness ~ stablelda_sim  + Sequence + QuestionHelpfulness  + logwords ', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "037498a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.445867\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                 4468\n",
      "Model:                          Logit   Df Residuals:                     4463\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sat, 19 Oct 2024   Pseudo R-squ.:                  0.1529\n",
      "Time:                        13:25:18   Log-Likelihood:                -1992.1\n",
      "converged:                       True   LL-Null:                       -2351.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.404e-154\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.2441      0.396     -0.616      0.538      -1.021       0.533\n",
      "stablelda_sim          -0.1094      0.404     -0.271      0.787      -0.901       0.682\n",
      "Sequence               -0.5982      0.031    -19.099      0.000      -0.660      -0.537\n",
      "QuestionHelpfulness     0.5637      0.045     12.548      0.000       0.476       0.652\n",
      "logwords                0.6261      0.048     13.046      0.000       0.532       0.720\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "## logit regression\n",
    "y, X = dmatrices('dummy ~ stablelda_sim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61ff2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "                       OLS      Logit  \n",
      "---------------------------------------\n",
      "Intercept           -0.114    -0.244   \n",
      "                    (0.110)   (0.396)  \n",
      "stablelda_sim       0.012     -0.109   \n",
      "                    (0.111)   (0.404)  \n",
      "Sequence            -0.248*** -0.598***\n",
      "                    (0.008)   (0.031)  \n",
      "QuestionHelpfulness 0.499***  0.564*** \n",
      "                    (0.012)   (0.045)  \n",
      "logwords            0.220***  0.626*** \n",
      "                    (0.013)   (0.048)  \n",
      "R-squared           0.371              \n",
      "R-squared Adj.      0.370              \n",
      "AIC                 10148.    3994.3   \n",
      "Log-Likelihood      -5069.1   -1992.1  \n",
      "=======================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "results = summary_col([ols_res, logit_res],stars=True,float_format='%0.3f',\n",
    "                  model_names=['OLS', 'Logit'],\n",
    "                  info_dict={'Log-Likelihood': lambda x: \"%#8.5g\" % x.llf,\n",
    "                     'AIC': lambda x: \"%#8.5g\" % x.aic} )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2407a5b",
   "metadata": {},
   "source": [
    "#### takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "face6a08",
   "metadata": {},
   "source": [
    "In the first linear regression model, the coefficient of QASimilarity (stablelda_sim) is 0.1784, and pvalue is 0.000\n",
    "\n",
    "In the second linear regression model, the coefficient of QASimilarity (stablelda_sim) is 0.1749, and pvalue is 0.000\n",
    "\n",
    "In the first logit regression model, the coefficient of QASimilarity (stablelda_sim) is 0.3992, and pvalue is 0.008\n",
    "\n",
    "In the second logit regression model, the coefficient of QASimilarity (stablelda_sim) is 0.4215, and pvalue is 0.005\n",
    "\n",
    "The effect size and pvalue is stable. To reproduce results in Figure 4 and Figure 5, please run Stable LDA 10 times, save the QASimilarity and regression results, and examine the effect size and p-value of QASimilarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bc9cf2",
   "metadata": {},
   "source": [
    "#### using LDA to infer topic vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8797ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02b98208",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/stackexchange.gaming.corpus.gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gensimcorpus \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload( \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/stackexchange.gaming.corpus.gensim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m id2word \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload( \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stackexchange.gaming.id2word.gensim\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mf:\\StableLDA\\StableLDA\\stable_lda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/stackexchange.gaming.corpus.gensim'"
     ]
    }
   ],
   "source": [
    "gensimcorpus = pickle.load( open('data/stackexchange.gaming.corpus.gensim', 'rb'))\n",
    "id2word = pickle.load( open('data/stackexchange.gaming.id2word.gensim', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab111c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51647, 5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gensimcorpus), len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a03bb",
   "metadata": {},
   "source": [
    "LDA first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "666b5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(gensimcorpus, num_topics= num_topics, alpha='symmetric', id2word=id2word, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9826667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_theta = []\n",
    "for bow in gensimcorpus:\n",
    "    prob = [ i[1] for i in lda_model.get_document_topics(bow, minimum_probability=0)]\n",
    "    lda_theta.append(prob)\n",
    "df['lda_sim'] = df.apply(lambda x:1-cosine(lda_theta[x['post_idx']], lda_theta[x['answer_idx']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60c77b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.340\n",
      "Model:                            OLS   Adj. R-squared:                  0.340\n",
      "Method:                 Least Squares   F-statistic:                     4239.\n",
      "Date:                Tue, 06 Sep 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:59:35   Log-Likelihood:                -37818.\n",
      "No. Observations:               32899   AIC:                         7.565e+04\n",
      "Df Residuals:                   32894   BIC:                         7.569e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.0975      0.017     -5.644      0.000      -0.131      -0.064\n",
      "lda_sim                 0.0029      0.026      0.112      0.911      -0.048       0.054\n",
      "Sequence               -0.2158      0.003    -75.587      0.000      -0.221      -0.210\n",
      "QuestionHelpfulness     0.4722      0.004    109.399      0.000       0.464       0.481\n",
      "logwords                0.2143      0.005     47.271      0.000       0.205       0.223\n",
      "==============================================================================\n",
      "Omnibus:                      323.846   Durbin-Watson:                   1.935\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              322.757\n",
      "Skew:                           0.227   Prob(JB):                     8.21e-71\n",
      "Kurtosis:                       2.828   Cond. No.                         27.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices(' AnswerHepfulness ~ lda_sim  + Sequence + QuestionHelpfulness  + logwords ', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8d1222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453824\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                32899\n",
      "Model:                          Logit   Df Residuals:                    32894\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 06 Sep 2022   Pseudo R-squ.:                  0.1413\n",
      "Time:                        10:59:36   Log-Likelihood:                -14930.\n",
      "converged:                       True   LL-Null:                       -17388.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.5329      0.058     -9.237      0.000      -0.646      -0.420\n",
      "lda_sim                -0.0471      0.088     -0.533      0.594      -0.220       0.126\n",
      "Sequence               -0.5234      0.011    -47.494      0.000      -0.545      -0.502\n",
      "QuestionHelpfulness     0.5378      0.016     33.393      0.000       0.506       0.569\n",
      "logwords                0.6557      0.017     39.488      0.000       0.623       0.688\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dummy ~ lda_sim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec89087",
   "metadata": {},
   "source": [
    "LDA second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adbb6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(gensimcorpus, num_topics= num_topics, alpha='symmetric', id2word=id2word, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f963465",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_theta = []\n",
    "for bow in gensimcorpus:\n",
    "    prob = [ i[1] for i in lda_model.get_document_topics(bow, minimum_probability=0)]\n",
    "    lda_theta.append(prob)\n",
    "df['lda_sim'] = df.apply(lambda x:1-cosine(lda_theta[x['post_idx']], lda_theta[x['answer_idx']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "873e2998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.340\n",
      "Model:                            OLS   Adj. R-squared:                  0.340\n",
      "Method:                 Least Squares   F-statistic:                     4239.\n",
      "Date:                Tue, 06 Sep 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:56:32   Log-Likelihood:                -37817.\n",
      "No. Observations:               32899   AIC:                         7.564e+04\n",
      "Df Residuals:                   32894   BIC:                         7.569e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.0992      0.017     -5.738      0.000      -0.133      -0.065\n",
      "lda_sim                 0.0252      0.027      0.936      0.349      -0.028       0.078\n",
      "Sequence               -0.2157      0.003    -75.582      0.000      -0.221      -0.210\n",
      "QuestionHelpfulness     0.4722      0.004    109.396      0.000       0.464       0.481\n",
      "logwords                0.2143      0.005     47.274      0.000       0.205       0.223\n",
      "==============================================================================\n",
      "Omnibus:                      323.723   Durbin-Watson:                   1.935\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              322.689\n",
      "Skew:                           0.227   Prob(JB):                     8.49e-71\n",
      "Kurtosis:                       2.828   Cond. No.                         28.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices(' AnswerHepfulness ~ lda_sim  + Sequence + QuestionHelpfulness  + logwords ', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6894939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453726\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                32899\n",
      "Model:                          Logit   Df Residuals:                    32894\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 06 Sep 2022   Pseudo R-squ.:                  0.1415\n",
      "Time:                        10:56:32   Log-Likelihood:                -14927.\n",
      "converged:                       True   LL-Null:                       -17388.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.5193      0.058     -9.004      0.000      -0.632      -0.406\n",
      "lda_sim                -0.2347      0.090     -2.610      0.009      -0.411      -0.058\n",
      "Sequence               -0.5237      0.011    -47.498      0.000      -0.545      -0.502\n",
      "QuestionHelpfulness     0.5379      0.016     33.396      0.000       0.506       0.569\n",
      "logwords                0.6557      0.017     39.484      0.000       0.623       0.688\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dummy ~ lda_sim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559cbb2",
   "metadata": {},
   "source": [
    "#### takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5becdc0b",
   "metadata": {},
   "source": [
    "In the first linear regression model, the coefficient of QASimilarity (lda_sim) is 0.0029, and pvalue is 0.991\n",
    "\n",
    "In the second linear regression model, the coefficient of QASimilarity (lda_sim) is 0.0252, and pvalue is 0.349\n",
    "\n",
    "In the first logit regression model, the coefficient of QASimilarity (lda_sim) is  -0.0471, and pvalue is 0.594 \n",
    "\n",
    "In the second logit regression model, the coefficient of QASimilarity (lda_sim) is -0.2347, and pvalue is 0.009\n",
    "\n",
    "The effect size and pvalue is unstable. Using Logit regression, the variable\\'s estimation is insignificant in the first run, but becomes significanly negative in the second run.\n",
    "\n",
    "This is the problem  using LDA for variable generation in regression analysis -- sometimes you get significant results but sometimes you get completely opposite results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ee9976",
   "metadata": {},
   "source": [
    "#### We conduct robustness check using TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25342d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76ab7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68647695",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfsim = []\n",
    "for idx, row in df.iterrows():\n",
    "    post_tfidf = X[row.post_idx].todense()\n",
    "    answer_tfidf = X[row.answer_idx].todense()\n",
    "    tfidfsim.append( 1-cosine(post_tfidf, answer_tfidf) )\n",
    "df['tfidfsim'] = pd.Series(list(tfidfsim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b590e",
   "metadata": {},
   "source": [
    "run regression to examine the relationship between QA similarity and answer helpfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d03e8454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       AnswerHepfulness   R-squared:                       0.342\n",
      "Model:                            OLS   Adj. R-squared:                  0.342\n",
      "Method:                 Least Squares   F-statistic:                     4267.\n",
      "Date:                Sat, 27 Aug 2022   Prob (F-statistic):               0.00\n",
      "Time:                        15:03:36   Log-Likelihood:                -37780.\n",
      "No. Observations:               32898   AIC:                         7.557e+04\n",
      "Df Residuals:                   32893   BIC:                         7.561e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.1350      0.018     -7.626      0.000      -0.170      -0.100\n",
      "tfidfsim                0.2017      0.024      8.524      0.000       0.155       0.248\n",
      "Sequence               -0.2130      0.003    -74.209      0.000      -0.219      -0.207\n",
      "QuestionHelpfulness     0.4732      0.004    109.719      0.000       0.465       0.482\n",
      "logwords                0.2068      0.005     44.829      0.000       0.198       0.216\n",
      "==============================================================================\n",
      "Omnibus:                      321.094   Durbin-Watson:                   1.935\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              319.622\n",
      "Skew:                           0.225   Prob(JB):                     3.94e-70\n",
      "Kurtosis:                       2.826   Cond. No.                         25.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('AnswerHepfulness ~ tfidfsim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.OLS(y, X)\n",
    "ols_res = model.fit()\n",
    "print(ols_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17dde146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453120\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  dummy   No. Observations:                32898\n",
      "Model:                          Logit   Df Residuals:                    32893\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sat, 27 Aug 2022   Pseudo R-squ.:                  0.1427\n",
      "Time:                        15:03:42   Log-Likelihood:                -14907.\n",
      "converged:                       True   LL-Null:                       -17388.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -0.6344      0.059    -10.738      0.000      -0.750      -0.519\n",
      "tfidfsim                0.5499      0.082      6.698      0.000       0.389       0.711\n",
      "Sequence               -0.5159      0.011    -46.666      0.000      -0.538      -0.494\n",
      "QuestionHelpfulness     0.5417      0.016     33.580      0.000       0.510       0.573\n",
      "logwords                0.6345      0.017     37.556      0.000       0.601       0.668\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dummy ~ tfidfsim  + Sequence + QuestionHelpfulness  + logwords', data=df, \n",
    "                 return_type='dataframe')\n",
    "model = sm.Logit(y, X)\n",
    "logit_res = model.fit()\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24050044",
   "metadata": {},
   "source": [
    "reproduce Table H "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a281e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "                       OLS      Logit  \n",
      "---------------------------------------\n",
      "Intercept           -0.135*** -0.634***\n",
      "                    (0.018)   (0.059)  \n",
      "tfidfsim            0.202***  0.550*** \n",
      "                    (0.024)   (0.082)  \n",
      "Sequence            -0.213*** -0.516***\n",
      "                    (0.003)   (0.011)  \n",
      "QuestionHelpfulness 0.473***  0.542*** \n",
      "                    (0.004)   (0.016)  \n",
      "logwords            0.207***  0.634*** \n",
      "                    (0.005)   (0.017)  \n",
      "AIC                 75571.    29823.   \n",
      "Log-Likelihood      -37780.   -14907.  \n",
      "=======================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "results = summary_col([ols_res, logit_res],stars=True,float_format='%0.3f',\n",
    "                  model_names=['OLS', 'Logit'],\n",
    "                  info_dict={'Log-Likelihood': lambda x: \"%#8.5g\" % x.llf,\n",
    "                     'AIC': lambda x: \"%#8.5g\" % x.aic} )\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_lda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
